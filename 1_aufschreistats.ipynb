{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysing #aufschrei with Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First of all, load all packages required for this analysis. (This list will be extended in the future - make sure you run it at each start.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymongo\n",
      "import json\n",
      "import os\n",
      "import nltk\n",
      "from nltk.collocations import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we will connect to the database. Please make sure you have either a local MongoDB instance running on your computer that contains the tweets, or an open SSH port forwarding connection to an existing database. (See README for details.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = pymongo.Connection('127.0.0.1', port=27017)\n",
      "aufschrei = con.aufschreirevisited.tweets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A quick overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's print the total number of tweets in the database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(str(aufschrei.count()) + \" Tweets total.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's find out how many of these tweets have been retweeted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_rt = aufschrei.find({\"retweeted_status\": {\"$exists\":\"true\"}}).count()\n",
      "print(str(count_rt) + \" Tweets were retweeted.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analysing all tweets as a text corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading all the tweets' text from the database into a corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cursor = aufschrei.find({},{\"text\":1})\n",
      "tweets = []    # a collection\n",
      "alltweets = '' # a text object\n",
      "for tweet in cursor:\n",
      "    tweets.append(tweet['text'])\n",
      "    alltweets += tweet['text'] + ' '"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Counting word frequencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* First, make the whole corpus lowercase (this step is needed for unification; because some users write all their tweets lowercase and some do not)\n",
      "* Next, tokenizing\n",
      "* Counting the tokens with to create a frequency distribution\n",
      "* Finally, sorting the frequency distribution and printing it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = nltk.word_tokenize(alltweets.lower()) # all lowercase\n",
      "text = nltk.Text(tokens) # tokenizing\n",
      "raw_freqs = nltk.FreqDist(text) # frequency distribution\n",
      "# printing the frequency list\n",
      "for item in sorted(raw_freqs, key=raw_freqs.get, reverse=True):\n",
      "    print(item + \" \"+str(raw_freqs[item]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A new function that filters stopwords and punctuation from the tokens:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_sw_punct(corpus):\n",
      "    from nltk.corpus import stopwords\n",
      "    from string import punctuation\n",
      "    mysw = stopwords.words('german') + ['dass','rt','http']\n",
      "    corpus = [t for t in corpus if t not in mysw and t not in punctuation]\n",
      "    return corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Counting and printing again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = remove_sw_punct(tokens) # apply the filter\n",
      "text = nltk.Text(tokens) # tokenizing\n",
      "freqs = nltk.FreqDist(text) # frequency distribution\n",
      "# printing the frequency list\n",
      "for item in sorted(freqs, key=freqs.get, reverse=True):\n",
      "    print(item + \" \"+str(freqs[item]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}