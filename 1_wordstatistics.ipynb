{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysing #aufschrei with Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First of all, load all packages required for this analysis. (This list will be extended in the future - make sure you run it at each start.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymongo\n",
      "import json\n",
      "import os\n",
      "import nltk\n",
      "from nltk.collocations import *\n",
      "from string import punctuation\n",
      "from nltk.draw import dispersion_plot"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If necessary: Download NLTK data (this has to be done only once)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.download('stopwords')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we will connect to the database. Please make sure you have either a local MongoDB instance running on your computer that contains the tweets, or an open SSH port forwarding connection to an existing database. (See README for details.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = pymongo.Connection('127.0.0.1', port=27017)\n",
      "aufschrei = con.aufschreirevisited.tweets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "A quick overview"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's print the total number of tweets in the database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count = aufschrei.count()\n",
      "print(count,\"Tweets total.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's find out how many of these tweets have been retweeted."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "count_rt = aufschrei.find({\"retweeted_status\": {\"$exists\":\"true\"}}).count()\n",
      "per = 100*count_rt/count\n",
      "print(count_rt,\"Tweets were retweeted. (\",str(per)[:4],\"%)\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Analysing all tweets as a text corpus"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading all the tweets' text from the database into a corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cursor = aufschrei.find({},{\"text\":1})\n",
      "tweets = []    # a collection\n",
      "alltweets = '' # a text object\n",
      "for tweet in cursor:\n",
      "    tweets.append(tweet['text'])\n",
      "    alltweets += tweet['text'] + ' '"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Counting word frequencies"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "* First, make the whole corpus lowercase (this step is needed for unification; because some users write all their tweets lowercase and some do not)\n",
      "* Next, tokenizing\n",
      "* Counting the tokens with to create a frequency distribution\n",
      "* Finally, sorting the frequency distribution and printing it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens = nltk.word_tokenize(alltweets.lower()) # all lowercase\n",
      "text = nltk.Text(tokens) # tokenizing\n",
      "raw_freqs = nltk.FreqDist(text) # frequency distribution"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rf_sort = sorted(raw_freqs, key=raw_freqs.get, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# printing the frequency list\n",
      "for rank, item in enumerate(rf_sort):\n",
      "    print(rank, item, raw_freqs[item])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A new function that removes tokens containing stopwords or punctuation:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def remove_sw_punct(corpus):\n",
      "    from nltk.corpus import stopwords\n",
      "    from string import punctuation\n",
      "    mysw = stopwords.words('german') + ['dass','rt','http']\n",
      "    # rand\n",
      "    puncts = punctuation + '\u201e\u201c\u201d\u00bb\u00ab\u203a\u2039\u2026\u2022\u00b4`\u2018\u2019\u2615\u25c6\u25ca\u2665\u2192\u266b\u2014\u2013'\n",
      "    # remove if stopword or containing punctuation\n",
      "    corpus = [t for t in corpus if t.lower() not in mysw and not any([p in t for p in list(puncts)])]\n",
      "    return corpus"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Counting and printing again"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokens_clean = remove_sw_punct(tokens) # apply filter\n",
      "text = nltk.Text(tokens_clean) # tokenizing\n",
      "freqs = nltk.FreqDist(text) # frequency distribution\n",
      "# printing the frequency list\n",
      "f_sort = sorted(freqs, key=freqs.get, reverse=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for rank, item in enumerate(f_sort):\n",
      "    print(rank, item, freqs[item])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Number of words in the text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(tokens)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Number of unique words in the text"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(raw_freqs.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Number of unique words in the text, ignoring stopwords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(freqs.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Text concordance - print context for several words, e.g. \"frauen\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text = nltk.Text(tokens)\n",
      "text.concordance('frauen')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.concordance('m\u00e4nner')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.concordance('139') # example for hashtag spam"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cooccurrences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.collocations()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Distribution of words by time"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['br\u00fcderle','marthadear','wizorek','alice','schwarzer'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['diskriminiert','diskriminieren','\u00fcbergriffe','angst','vergewaltigung'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['k\u00fcche','emanze','emanzen','hysterisch','hysterische','\u00fcberfl\u00fcssig',\n",
      "                            'fotze','fotzen','jammern','gejammer','verschw\u00f6rung','terror'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['bushaltestelle','haltestelle','bahn','heimweg','disco','konzert','caf\u00e9'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['schule','arbeit','uni','universit\u00e4t','sport','ausbildung','azubi',\n",
      "                            'betrieb'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['internet','twitter','debatte','bel\u00e4stigung'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['chef','kollege','kollegen','lehrer','arzt','trainer'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['mutter','vater','bruder','schwester','kind','kinder'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['arschl\u00f6cher','jungs','m\u00e4dels','m\u00e4dchen'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.dispersion_plot(words=['ja','nein'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Common contexts of words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.common_contexts(words=['m\u00e4nner'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text.common_contexts(words=['frauen'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}