{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysing #aufschrei with Python"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Part 2: Collocations and ngrams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Loading packages, connecting database."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import nltk\n",
      "import os\n",
      "import pymongo\n",
      "import re\n",
      "from nltk.collocations import *\n",
      "from nltk.util import ngrams\n",
      "from string import punctuation\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = pymongo.Connection('127.0.0.1', port=27017)\n",
      "aufschrei = con.aufschreirevisited.tweets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Load Tweets into a collection"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nortre = re.compile(\"^(?!RT).+\",re.IGNORECASE) # matches everything thats not a manual RT\n",
      "aufschrei.create_index('created_at', pymongo.ASCENDING)\n",
      "cursor = aufschrei.find({\"retweeted_status\": {\"$exists\":False}, \"text\":nortre},\n",
      "                        {'text' : 1}).sort('created_at', 1)\n",
      "utweets = []    # a collection\n",
      "for tweet in cursor:\n",
      "    utweets.append(tweet['text'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Close database connection:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tokenizing function to split tweets into words, preserving Twitter usernames and hashtags"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def twitter_tokenize(text):\n",
      "    text = re.sub('&.+?;',' ',text) # remove html entities\n",
      "    text = re.sub('https?:.+? ','_URL_ ',text) # remove URLs\n",
      "    text = re.sub('https?:.+?$','_URL_',text) # remove URLs\n",
      "    tokens = re.split('[\\s.,;!?:()\\[\\]\\|\u201c\"\u2026=+/]',text)\n",
      "    tok2 = []\n",
      "    # matches all special chars except #@_\n",
      "    pattern = re.compile('^[^\\w_@#]',re.UNICODE)\n",
      "    # multiple occurrences of special chars except #@_\n",
      "    replacepattern = re.compile('^[^\\w_@#]*',re.UNICODE)\n",
      "    for t in tokens:\n",
      "        if len(re.findall('\\w.*',t)) > 0: # clear tokens consisting of only special chars\n",
      "            if re.match(pattern,t): # find pattern at the beginning of the word\n",
      "                t = re.sub(replacepattern,'',t)\n",
      "            t = t[::-1] # reverse token\n",
      "            if re.match(pattern,t): # find at the end of the word\n",
      "                t = re.sub(replacepattern,'',t)\n",
      "            t = t[::-1] # flip back\n",
      "            tok2.append(t)\n",
      "    return tok2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some preprocessing: Make everything lowercase and remove some Tweets containing obvious spam"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lowercase\n",
      "utweets = [t.lower() for t in utweets]\n",
      "print('before:', len(utweets))\n",
      "# filter some spam out\n",
      "utweets = [t for t in utweets if not \n",
      "           re.search(\"insolvenzeinkauf|steuerhinterzieher|drecksau:\",t)]\n",
      "print('after: ', len(utweets))\n",
      "utweets[-1] #check"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Tokenize Tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twtok = [twitter_tokenize(t) for t in utweets]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twtok[-1] #check"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Most common Tweets"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's first have a look at the most common Tweets that are not Retweets (= Retweets done either via the web interface or manually).\n",
      "Every Tweet is a series of tokens now. Let's count these series to see which of them occur most often in our corpus."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tuple(twtok[0])\n",
      "twtupl = [tuple(i) for i in twtok]\n",
      "c = Counter(twtupl)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We need a small function to pretty-print the results:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes an ngram counter object and prints the first n items in it\n",
      "def print_grams(cgrams, n):\n",
      "    cgrams = cgrams.most_common(n)\n",
      "    for item in cgrams:\n",
      "        print(item[1], ' '.join(item[0]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The most common 25 Tweets with the same content:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print_grams(c,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some are recommendations (\"#aufschrei\", \"#ff #aufschrei\", \"lest #aufschrei\"), \n",
      "plenty are shared news articles containing the headline and possibly a link to an online newspaper, \n",
      "some are spam as well (\"#videoproduktion #iphone_5 #photoproduction #aufschrei\"), \n",
      "indicating that the well-known hashtag has been piggybanked by some to reach more people with spam messages."
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "ngrams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A function that creates ngrams of each Tweet and counts their total occurrence. (It's important to do the ngram counts on individual Tweet level, so we don't get ngrams overlapping between Tweets that don't belong together.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes tokens separated by tweets, a number, and returns a counter object\n",
      "def gramcount(tokens, n):\n",
      "    grams = [list(ngrams(t,n)) for t in tokens] # calculate ngrams for each Tweet\n",
      "    grams = [i for sublist in grams for i in sublist] # flatten list\n",
      "    return(Counter(grams))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Calculating ngrams!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigrams = gramcount(twtok,2)\n",
      "print_grams(bigrams, 25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trigrams = gramcount(twtok,3)\n",
      "print_grams(trigrams, 25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fourgrams = gramcount(twtok,4)\n",
      "print_grams(fourgrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fivegrams = gramcount(twtok,5)\n",
      "print_grams(fivegrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sixgrams = gramcount(twtok,6)\n",
      "print_grams(sixgrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sevengrams = gramcount(twtok,7)\n",
      "print_grams(sevengrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "eightgrams = gramcount(twtok,8)\n",
      "print_grams(eightgrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ninegrams = gramcount(twtok,9)\n",
      "print_grams(ninegrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tengrams = gramcount(twtok,10)\n",
      "print_grams(tengrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Adapt numbers as needed."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ngrams = gramcount(twtok,20)\n",
      "print_grams(ngrams,25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}