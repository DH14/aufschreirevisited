{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Analysing #aufschrei with Python"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import nltk\n",
      "import os\n",
      "import pandas\n",
      "import pymongo\n",
      "import re\n",
      "from nltk.collocations import *\n",
      "from nltk.draw import dispersion_plot\n",
      "from nltk.util import ngrams\n",
      "from string import punctuation\n",
      "from collections import Counter"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = pymongo.Connection('127.0.0.1', port=27017)\n",
      "aufschrei = con.aufschreirevisited.tweets"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nortre = re.compile(\"^(?!RT).+\",re.IGNORECASE) # matches everything thats not a manual RT\n",
      "cursor = aufschrei.find({\"retweeted_status\": {\"$exists\":False}, \"text\":nortre},{'text' : 1}).sort('created_at', 1)\n",
      "utweets = []    # a collection\n",
      "for tweet in cursor:\n",
      "    utweets.append(tweet['text'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def twitter_tokenize(text):\n",
      "    text = re.sub('&.+?;',' ',text) # remove html entities\n",
      "    text = re.sub('https?:.+? ',' ',text) # remove URLs\n",
      "    text = re.sub('https?:.+?$',' ',text) # remove URLs\n",
      "    tokens = re.split('[\\s.,;!?:()\\[\\]\\|\u201c\"\u2026=+/]',text)\n",
      "    tok2 = []\n",
      "    pattern = re.compile('^[^\\w_@#]',re.UNICODE) # matches all special chars except #@_\n",
      "    replacepattern = re.compile('^[^\\w_@#]*',re.UNICODE) # multiple occurrences of special chars except #@_\n",
      "    for t in tokens:\n",
      "        if len(re.findall('\\w.*',t)) > 0: # clear tokens consisting of only interpunctuation\n",
      "            if re.match(pattern,t): # find pattern at the beginning of the word\n",
      "                t = re.sub(replacepattern,'',t)\n",
      "            t = t[::-1] # reverse\n",
      "            if re.match(pattern,t): # find at the end of the word\n",
      "                t = re.sub(replacepattern,'',t)\n",
      "            t = t[::-1] # flip back\n",
      "            tok2.append(t)\n",
      "    return tok2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# lowercase\n",
      "utweets = [t.lower() for t in utweets]\n",
      "print(len(utweets))\n",
      "utweets = [t for t in utweets if not re.search(\"insolvenzeinkauf|steuerhinterzieher|drecksau:\",t)]\n",
      "print(len(utweets))\n",
      "utweets[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#len(utweets)\n",
      "twtok = [twitter_tokenize(t) for t in utweets]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "twtok[-10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# takes tokens separated by tweets, a number, and returns a counter object\n",
      "def gramcount(tokens, n):\n",
      "    grams = [list(ngrams(t,n)) for t in tokens]\n",
      "    grams = [i for sublist in grams for i in sublist] # flatten list\n",
      "    return(Counter(grams))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bgrms = [list(ngrams(t,2)) for t in twtok]\n",
      "print(len(bgrms))\n",
      "bgrms = [item for sublist in bgrms for item in sublist] # flatten list\n",
      "#t = list(t)\n",
      "print(len(bgrms))\n",
      "#words = re.findall(r'\\w+', open('hamlet.txt').read().lower())\n",
      "c = Counter(bgrms).most_common(25)\n",
      "c"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "trigrams = gramcount(twtok,3)\n",
      "print(trigrams.most_common(50))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fourgrams = gramcount(twtok,4)\n",
      "print(fourgrams.most_common(50))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fourgrams = gramcount(twtok,5)\n",
      "print(fourgrams.most_common(50))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fourgrams = gramcount(twtok,6)\n",
      "print(fourgrams.most_common(50))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}